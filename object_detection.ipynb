{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1: Import Required Libraries"
      ],
      "metadata": {
        "id": "h_41GMH0PFJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import pyttsx3\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "bfNZthcsPVT7",
        "outputId": "90b75ba8-2e24-4ea9-f6ab-48f5f9d423dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1011997153.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyttsx3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2: Environment Configuration**"
      ],
      "metadata": {
        "id": "RNKApsSzPZ43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix OpenMP duplicate library issue\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
      ],
      "metadata": {
        "id": "xb1kwTJdPi4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3: Initialize Text-to-Speech Engine**"
      ],
      "metadata": {
        "id": "JSoVSDXWPn4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    engine = pyttsx3.init()\n",
        "    engine.setProperty('rate', 150)\n",
        "    print(\"Text-to-Speech initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"TTS Error: {e}\")\n",
        "    engine = None\n"
      ],
      "metadata": {
        "id": "nhbyAklHPvKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4: Load YOLO Model and Class Names**"
      ],
      "metadata": {
        "id": "dDTvvkmPPvmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"yolo11n.pt\"\n",
        "\n",
        "classNames = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
        "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear'\n",
        "]\n",
        "\n",
        "print(\"Loading YOLO model...\")\n",
        "model = YOLO(model_path)\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "0WI6Z-u5Pv9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5: Camera Initialization**"
      ],
      "metadata": {
        "id": "K-ghbjDqY4bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Cannot open camera\")\n",
        "\n",
        "print(\"Camera started.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "v3W2gd0DY5lj",
        "outputId": "6775dc38-653e-417f-e3f4-53fc8b82b8e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Cannot open camera",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2436097362.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot open camera\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Camera started.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot open camera"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: Video Writer (Save Output)"
      ],
      "metadata": {
        "id": "5Ks_Utu_P9a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(\n",
        "    'output.avi',\n",
        "    fourcc,\n",
        "    20.0,\n",
        "    (int(cap.get(3)), int(cap.get(4)))\n",
        ")\n"
      ],
      "metadata": {
        "id": "uOWEU8VxZPNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7: Data Storage & Counters**"
      ],
      "metadata": {
        "id": "M7XiKeloZT_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Class', 'Confidence', 'Time'])\n",
        "\n",
        "object_counter = defaultdict(int)\n",
        "last_spoken = {}\n",
        "speech_delay = 2  # seconds\n"
      ],
      "metadata": {
        "id": "L0pMzzV0ZUSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8: FPS & Confidence Trackbar**"
      ],
      "metadata": {
        "id": "8uXxdeY1ZcjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev_time = 0\n",
        "\n",
        "def nothing(x):\n",
        "    pass\n",
        "\n",
        "cv2.namedWindow(\"YOLO Real-Time Detection\")\n",
        "cv2.createTrackbar(\n",
        "    \"Confidence\",\n",
        "    \"YOLO Real-Time Detection\",\n",
        "    40, 100,\n",
        "    nothing\n",
        ")\n"
      ],
      "metadata": {
        "id": "NZeFFBHXZc7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9: Real-Time Detection Loop**"
      ],
      "metadata": {
        "id": "rInmsmnxZkSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Press 'Q' to quit\")\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # FPS calculation\n",
        "    curr_time = time.time()\n",
        "    fps = 1 / (curr_time - prev_time) if prev_time != 0 else 0\n",
        "    prev_time = curr_time\n",
        "\n",
        "    conf_threshold = cv2.getTrackbarPos(\n",
        "        \"Confidence\",\n",
        "        \"YOLO Real-Time Detection\"\n",
        "    ) / 100\n",
        "\n",
        "    results = model(frame, stream=True)\n",
        "\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = float(box.conf[0])\n",
        "            cls = int(box.cls[0])\n",
        "\n",
        "            if cls >= len(classNames) or conf < conf_threshold:\n",
        "                continue\n",
        "\n",
        "            class_name = classNames[cls]\n",
        "            label = f\"{class_name} {conf:.2f}\"\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(\n",
        "                frame, label, (x1, y1 - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2\n",
        "            )\n",
        "\n",
        "            # Count objects\n",
        "            object_counter[class_name] += 1\n",
        "\n",
        "            # Save detection\n",
        "            df.loc[len(df)] = [\n",
        "                class_name,\n",
        "                conf,\n",
        "                time.strftime(\"%H:%M:%S\")\n",
        "            ]\n",
        "\n",
        "            # Voice feedback\n",
        "            if engine:\n",
        "                last_time = last_spoken.get(class_name, 0)\n",
        "                if curr_time - last_time > speech_delay:\n",
        "                    engine.say(f\"Detected {class_name}\")\n",
        "                    engine.runAndWait()\n",
        "                    last_spoken[class_name] = curr_time\n",
        "\n",
        "    # Display FPS\n",
        "    cv2.putText(\n",
        "        frame, f\"FPS: {int(fps)}\",\n",
        "        (20, 40),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2\n",
        "    )\n",
        "\n",
        "    # Display counters\n",
        "    y_offset = 80\n",
        "    for obj, count in object_counter.items():\n",
        "        cv2.putText(\n",
        "            frame, f\"{obj}: {count}\",\n",
        "            (20, y_offset),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2\n",
        "        )\n",
        "        y_offset += 25\n",
        "\n",
        "    cv2.imshow(\"YOLO Real-Time Detection\", frame)\n",
        "    out.write(frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n"
      ],
      "metadata": {
        "id": "H94WtdyoZkky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10: Release Camera & Windows**"
      ],
      "metadata": {
        "id": "s2uBa9QeZppE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Camera stopped.\")\n"
      ],
      "metadata": {
        "id": "WmjcAuR3Zp4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11: Save Results to Excel**"
      ],
      "metadata": {
        "id": "L1XGAMDEZ6Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"realtime_detections.xlsx\", index=False)\n",
        "\n",
        "print(\"Detections saved.\")\n",
        "print(f\"Total detections: {len(df)}\")\n"
      ],
      "metadata": {
        "id": "UseueDg1Z6jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12: Show Detection Table**"
      ],
      "metadata": {
        "id": "AWTRaHaaaE0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "np0aI0GRaFCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}